{"id": "2508.15070", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2508.15070", "abs": "https://arxiv.org/abs/2508.15070", "authors": ["Daichi Amagata"], "title": "Random Sampling over Spatial Range Joins", "comment": "Accepted version of our ICDE2025 paper", "summary": "Spatial range joins have many applications, including geographic information\nsystems, location-based social networking services, neuroscience, and\nvisualization. However, joins incur not only expensive computational costs but\nalso too large result sets. A practical and reasonable approach to alleviating\nthese issues is to return random samples of the join results. Although this is\npromising and sufficient for many applications involving spatial range joins,\nefficiently computing random samples is not trivial. This is because we must\nobtain random join samples without running spatial range joins. We address this\nchallenging problem for the first time and aim at designing a time- and\nspace-efficient algorithm. First, we design two baseline algorithms that employ\nexisting techniques for random sampling and show that they are not efficient.\nThen, we propose a new data structure that can deal with our problem in\n$\\tilde{O}(n + m + t)$ expected time and $O(n+m)$ space, where $n$ and $m$ are\nthe sizes of two point sets and $t$ is the required number of samples. We\nconduct extensive experiments using four real spatial datasets, and the results\ndemonstrate that our algorithm is significantly faster than the baselines in\nmost tests."}
{"id": "2508.15238", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2508.15238", "abs": "https://arxiv.org/abs/2508.15238", "authors": ["Yinyu Liu", "Kaiqiang Yu", "Shengxin Liu", "Cheng Long", "Zhaoquan Gu"], "title": "Temporal $k$-Core Query, Revisited", "comment": null, "summary": "Querying cohesive subgraphs in temporal graphs is essential for understanding\nthe dynamic structure of real-world networks, such as evolving communities in\nsocial platforms, shifting hyperlink structures on the Web, and transient\ncommunication patterns in call networks. Recently, research has focused on the\ntemporal $k$-core query, which aims to identify all $k$-cores across all\npossible time sub-intervals within a given query interval. The state-of-the-art\nalgorithm OTCD mitigates redundant computations over overlapping sub-intervals\nby exploiting inclusion relationships among $k$-cores in different time\nintervals. Nevertheless, OTCD remains limited in scalability due to the\ncombinatorial growth in interval enumeration and repeated processing. In this\npaper, we revisit the temporal $k$-core query problem and introduce a novel\nalgorithm CoreT, which dynamically records the earliest timestamp at which each\nvertex or edge enters a $k$-core. This strategy enables substantial pruning of\nredundant computations. As a result, CoreT requires only a single pass over the\nquery interval and achieves improved time complexity, which is linear in both\nthe number of temporal edges within the query interval and the duration of the\ninterval, making it highly scalable for long-term temporal analysis.\nExperimental results on large real-world datasets show that CoreT achieves up\nto four orders of magnitude speedup compared to the existing state-of-the-art\nOTCD, demonstrating its effectiveness and scalability for temporal $k$-core\nanalysis."}
{"id": "2508.15276", "categories": ["cs.DB", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15276", "abs": "https://arxiv.org/abs/2508.15276", "authors": ["Zhongjun Ding", "Yin Lin", "Tianjing Zeng"], "title": "AmbiSQL: Interactive Ambiguity Detection and Resolution for Text-to-SQL", "comment": null, "summary": "Text-to-SQL systems translate natural language questions into SQL queries,\nproviding substantial value for non-expert users. While large language models\n(LLMs) show promising results for this task, they remain error-prone. Query\nambiguity has been recognized as a major obstacle for LLM-based Text-to-SQL\nsystems, leading to misinterpretation of user intent and inaccurate SQL\ngeneration. We demonstrate AmbiSQL, an interactive system that automatically\ndetects query ambiguities and guides users through intuitive multiple-choice\nquestions to clarify their intent. Our approach introduces a fine-grained\nambiguity taxonomy for identifying ambiguities that affect database element\nmapping and LLM reasoning, then incorporates user feedback to rewrite ambiguous\nquestions. Evaluation on an ambiguous query dataset shows that AmbiSQL achieves\n87.2% precision in ambiguity detection and improves SQL exact match accuracy by\n50% when integrated with Text-to-SQL systems. Our demonstration showcases the\nsignificant performance gains and highlights the system's practical usability.\nCode repo and demonstration are available at:\nhttps://github.com/JustinzjDing/AmbiSQL."}
{"id": "2508.15285", "categories": ["cs.DB", "C.2.4; H.2.4; D.2.11"], "pdf": "https://arxiv.org/pdf/2508.15285", "abs": "https://arxiv.org/abs/2508.15285", "authors": ["Chunyu Zhao", "Hongzhi Wang", "Kaixin Zhang", "Hongliang Li", "Yihan Zhang", "Jiawei Zhang", "Kunkai Gu", "Yuan Tian", "Xiangdong Huang", "Jingyi Xu"], "title": "Efficient Cloud-Edge-Device Query Execution Based on Collaborative Scan Operator", "comment": "12 pages, 23 figures. Submitted to IEEE Transactions on ICDE", "summary": "In cloud-edge-device (CED) collaborative query (CQ) processing, by leveraging\nCED collaboration, the advantages of both cloud computing and edge resources\ncan be fully integrated. However, it is difficult to implement collaborative\noperators that can flexibly switch between the cloud and the edge during query\nexecution. Thus, in this paper, we aim to improve the query performance when\nthe edge resources reach a bottleneck. To achieve seamless switching of query\nexecution between the cloud and edge, we propose a CQ processing method by\nestablishing a CED collaborative framework based on the collaborative scan\noperator, so that query execution can be transferred to the cloud at any time\nwhen the edge resources are saturated. Extensive experiments show that, under\nsufficient network download bandwidth, the CED collaborative scan operator can\neffectively alleviate the performance degradation of scan operators caused by\nhigh I/O load and CPU wait time at the edge. It also achieves balanced resource\nscheduling between the cloud and edge."}
{"id": "2508.15290", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2508.15290", "abs": "https://arxiv.org/abs/2508.15290", "authors": ["Peiqi Yin", "Xiao Yan", "Qihui Zhou", "Hui Li", "Xiaolu Li", "Lin Zhang", "Meiling Wang", "Xin Yao", "James Cheng"], "title": "Gorgeous: Revisiting the Data Layout for Disk-Resident High-Dimensional Vector Search", "comment": "12 pages, 19 figures", "summary": "Similarity-based vector search underpins many important applications, but a\nkey challenge is processing massive vector datasets (e.g., in TBs). To reduce\ncosts, some systems utilize SSDs as the primary data storage. They employ a\nproximity graph, which connects similar vectors to form a graph and is the\nstate-of-the-art index for vector search. However, these systems are hindered\nby sub-optimal data layouts that fail to effectively utilize valuable memory\nspace to reduce disk access and suffer from poor locality for accessing\ndisk-resident data. Through extensive profiling and analysis, we found that the\nstructure of the proximity graph index is accessed more frequently than the\nvectors themselves, yet existing systems do not distinguish between the two. To\naddress this problem, we design the Gorgeous system with the principle of\nprioritizing graph structure over vectors. Specifically, Gorgeous features a\nmemory cache that keeps the adjacency lists of graph nodes to improve cache\nhits and a disk block format that explicitly stores neighbors' adjacency lists\nalong with a vector to enhance data locality. Experimental results show that\nGorgeous consistently outperforms two state-of-the-art disk-based systems for\nvector search, boosting average query throughput by over 60% and reducing query\nlatency by over 35%."}
{"id": "2508.15694", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2508.15694", "abs": "https://arxiv.org/abs/2508.15694", "authors": ["Yijie Zhou", "Shengyuan Lin", "Shufeng Gong", "Song Yu", "Shuhao Fan", "Yanfeng Zhang", "Ge Yu"], "title": "GoVector: An I/O-Efficient Caching Strategy for High-Dimensional Vector Nearest Neighbor Search", "comment": "12 pages, 12 figures, this paper is the English version of our\n  Chinese paper accepted for publication in Journal of Software, Vol. 37, No.\n  3, 2026", "summary": "Graph-based high-dimensional vector indices have become a mainstream solution\nfor large-scale approximate nearest neighbor search (ANNS). However, their\nsubstantial memory footprint often requires storage on secondary devices, where\nfrequent on-demand loading of graph and vector data leads to I/O becoming the\ndominant bottleneck, accounting for over 90\\% of query latency. Existing static\ncaching strategies mitigate this issue only in the initial navigation phase by\npreloading entry points and multi-hop neighbors, but they fail in the second\nphase where query-dependent nodes must be dynamically accessed to achieve high\nrecall. We propose GoVector, an I/O-efficient caching strategy tailored for\ndisk-based graph indices. GoVector combines (1) a static cache that stores\nentry points and frequently accessed neighbors, and (2) a dynamic cache that\nadaptively captures nodes with high spatial locality during the second search\nphase. To further align storage layout with similarity-driven search patterns,\nGoVector reorders nodes on disk so that similar vectors are colocated on the\nsame or adjacent pages, thereby improving locality and reducing I/O overhead.\nExtensive experiments on multiple public datasets show that GoVector achieves\nsubstantial performance improvements. At 90% recall, it reduces I/O operations\nby 46% on average, increases query throughput by 1.73x, and lowers query\nlatency by 42% compared to state-of-the-art disk-based graph indexing systems."}
