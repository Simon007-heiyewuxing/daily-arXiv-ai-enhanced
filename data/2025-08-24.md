<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 6]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Random Sampling over Spatial Range Joins](https://arxiv.org/abs/2508.15070)
*Daichi Amagata*

Main category: cs.DB

TL;DR: 该文首次研究在不执行完整连接的前提下对空间范围连接进行随机采样，提出新数据结构实现近线性复杂度并在实验中表现优越。


<details>
  <summary>Details</summary>
Motivation: 空间范围连接应用广泛但产生的结果集巨大且计算代价高，返回随机样本可缓解问题，但要在不实际运行范围连接的情况下得到随机样本是具有挑战性的。

Method: 先设计两个使用现有随机采样技术的基线算法并证明其低效，然后提出一种新的数据结构，能够在\tilde{O}(n+m+t) 期望时间和 O(n+m) 空间内生成 t 个样本。

Result: 构建的数据结构在理论上达到了近线性时间和线性空间复杂度，实验（四个真实数据集）显示在大多数测试场景下显著快于基线。

Conclusion: 论文提出了首个针对空间范围连接随机采样的问题的高效算法，证明在时间和空间上均有优势，且实验验证优于基线算法。

Abstract: Spatial range joins have many applications, including geographic information
systems, location-based social networking services, neuroscience, and
visualization. However, joins incur not only expensive computational costs but
also too large result sets. A practical and reasonable approach to alleviating
these issues is to return random samples of the join results. Although this is
promising and sufficient for many applications involving spatial range joins,
efficiently computing random samples is not trivial. This is because we must
obtain random join samples without running spatial range joins. We address this
challenging problem for the first time and aim at designing a time- and
space-efficient algorithm. First, we design two baseline algorithms that employ
existing techniques for random sampling and show that they are not efficient.
Then, we propose a new data structure that can deal with our problem in
$\tilde{O}(n + m + t)$ expected time and $O(n+m)$ space, where $n$ and $m$ are
the sizes of two point sets and $t$ is the required number of samples. We
conduct extensive experiments using four real spatial datasets, and the results
demonstrate that our algorithm is significantly faster than the baselines in
most tests.

</details>


### [2] [Temporal $k$-Core Query, Revisited](https://arxiv.org/abs/2508.15238)
*Yinyu Liu,Kaiqiang Yu,Shengxin Liu,Cheng Long,Zhaoquan Gu*

Main category: cs.DB

TL;DR: CoreT通过记录元素进入k-core的最早时间并单次线性扫描区间，显著剪枝冗余，实验证明比OTCD快最多10000倍，适合长时段的时序k-core查询。


<details>
  <summary>Details</summary>
Motivation: 现有OTCD算法虽利用包含关系减少重复，但在区间枚举上仍呈组合爆炸，难以扩展到长时段分析。

Method: CoreT动态维护每个顶点/边进入k-core的最早时间，并基于此信息在查询区间内单次从左到右扫描时间戳，避免对重叠子区间的重复处理。

Result: 在大规模真实数据集上，CoreT相较于OTCD最高可达四个数量级的加速，时间复杂度为O(#时间边 × 区间长度)，对长时序分析表现出高可扩展性。

Conclusion: 提出CoreT算法，通过记录顶点/边进入k-core的最早时间戳，实现单次线性扫描查询区间，能有效剪枝冗余计算。

Abstract: Querying cohesive subgraphs in temporal graphs is essential for understanding
the dynamic structure of real-world networks, such as evolving communities in
social platforms, shifting hyperlink structures on the Web, and transient
communication patterns in call networks. Recently, research has focused on the
temporal $k$-core query, which aims to identify all $k$-cores across all
possible time sub-intervals within a given query interval. The state-of-the-art
algorithm OTCD mitigates redundant computations over overlapping sub-intervals
by exploiting inclusion relationships among $k$-cores in different time
intervals. Nevertheless, OTCD remains limited in scalability due to the
combinatorial growth in interval enumeration and repeated processing. In this
paper, we revisit the temporal $k$-core query problem and introduce a novel
algorithm CoreT, which dynamically records the earliest timestamp at which each
vertex or edge enters a $k$-core. This strategy enables substantial pruning of
redundant computations. As a result, CoreT requires only a single pass over the
query interval and achieves improved time complexity, which is linear in both
the number of temporal edges within the query interval and the duration of the
interval, making it highly scalable for long-term temporal analysis.
Experimental results on large real-world datasets show that CoreT achieves up
to four orders of magnitude speedup compared to the existing state-of-the-art
OTCD, demonstrating its effectiveness and scalability for temporal $k$-core
analysis.

</details>


### [3] [AmbiSQL: Interactive Ambiguity Detection and Resolution for Text-to-SQL](https://arxiv.org/abs/2508.15276)
*Zhongjun Ding,Yin Lin,Tianjing Zeng*

Main category: cs.DB

TL;DR: AmbiSQL自动识别并通过多项选择交互澄清用户查询歧义，显著提高Text-to-SQL系统的准确率和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在Text-to-SQL任务中易受查询歧义影响，导致误解用户意图和生成错误SQL；因此需要一种自动化交互方式检测并消除歧义，以提升系统可靠性和可用性。

Method: 构建细粒度歧义分类法（针对数据库元素映射和LLM推理的歧义），使用分类器检测歧义并生成多项选择澄清问题，基于用户反馈对原始自然语言查询进行改写，随后将改写结果输入现有Text-to-SQL模型生成SQL。

Result: 在一个歧义查询数据集上的评估表明：歧义检测精确率达87.2%，与Text-to-SQL系统集成后，SQL精准匹配（exact match）提升了50%。

Conclusion: 该论文提出了AmbiSQL，一种交互式Text-to-SQL系统，通过自动检测查询歧义并用多项选择问题引导用户澄清意图，从而提高SQL生成准确率。

Abstract: Text-to-SQL systems translate natural language questions into SQL queries,
providing substantial value for non-expert users. While large language models
(LLMs) show promising results for this task, they remain error-prone. Query
ambiguity has been recognized as a major obstacle for LLM-based Text-to-SQL
systems, leading to misinterpretation of user intent and inaccurate SQL
generation. We demonstrate AmbiSQL, an interactive system that automatically
detects query ambiguities and guides users through intuitive multiple-choice
questions to clarify their intent. Our approach introduces a fine-grained
ambiguity taxonomy for identifying ambiguities that affect database element
mapping and LLM reasoning, then incorporates user feedback to rewrite ambiguous
questions. Evaluation on an ambiguous query dataset shows that AmbiSQL achieves
87.2% precision in ambiguity detection and improves SQL exact match accuracy by
50% when integrated with Text-to-SQL systems. Our demonstration showcases the
significant performance gains and highlights the system's practical usability.
Code repo and demonstration are available at:
https://github.com/JustinzjDing/AmbiSQL.

</details>


### [4] [Efficient Cloud-Edge-Device Query Execution Based on Collaborative Scan Operator](https://arxiv.org/abs/2508.15285)
*Chunyu Zhao,Hongzhi Wang,Kaixin Zhang,Hongliang Li,Yihan Zhang,Jiawei Zhang,Kunkai Gu,Yuan Tian,Xiangdong Huang,Jingyi Xu*

Main category: cs.DB

TL;DR: 提出一种基于协同扫描算子的 CED 协作框架，支持边缘资源饱和时将查询执行无缝迁移到云端，实验在高带宽下验证了其性能和资源均衡效果。


<details>
  <summary>Details</summary>
Motivation: 在云-边-端协同查询处理中，边缘资源（I/O 和 CPU）达到瓶颈时，难以灵活地在云和边之间切换执行以维持查询性能，因此需要一种可以无缝切换执行位置的协作算子。

Method: 提出了基于协同扫描算子的 CED 协作框架，支持在查询执行过程中动态将扫描操作从边缘迁移到云端，利用云端计算与边缘资源结合，通过网络下载将数据转移到云端继续执行。

Result: 实验表明，在充足网络下载带宽条件下，协同扫描算子能有效减轻因边缘高 I/O 负载和 CPU 等待导致的扫描性能下降，并实现云边之间的资源均衡调度。

Conclusion: 基于协同扫描算子的 CED 协作框架能够在边缘资源饱和时无缝将查询执行切换到云端，从而缓解边缘扫描算子性能下降并实现云边资源负载均衡。

Abstract: In cloud-edge-device (CED) collaborative query (CQ) processing, by leveraging
CED collaboration, the advantages of both cloud computing and edge resources
can be fully integrated. However, it is difficult to implement collaborative
operators that can flexibly switch between the cloud and the edge during query
execution. Thus, in this paper, we aim to improve the query performance when
the edge resources reach a bottleneck. To achieve seamless switching of query
execution between the cloud and edge, we propose a CQ processing method by
establishing a CED collaborative framework based on the collaborative scan
operator, so that query execution can be transferred to the cloud at any time
when the edge resources are saturated. Extensive experiments show that, under
sufficient network download bandwidth, the CED collaborative scan operator can
effectively alleviate the performance degradation of scan operators caused by
high I/O load and CPU wait time at the edge. It also achieves balanced resource
scheduling between the cloud and edge.

</details>


### [5] [Gorgeous: Revisiting the Data Layout for Disk-Resident High-Dimensional Vector Search](https://arxiv.org/abs/2508.15290)
*Peiqi Yin,Xiao Yan,Qihui Zhou,Hui Li,Xiaolu Li,Lin Zhang,Meiling Wang,Xin Yao,James Cheng*

Main category: cs.DB

TL;DR: 通过优先缓存和布局近邻图结构，Gorgeous显著减少磁盘访问并提升磁盘型向量检索性能。


<details>
  <summary>Details</summary>
Motivation: 在大规模向量检索中，近似最近邻常用的近邻图索引结构比向量本身被更频繁访问，但现有系统未对图结构与向量做差异化处理，导致磁盘访问和局部性低效。

Method: 设计了一个内存缓存用于存储图节点的邻接列表，以及一种磁盘块格式，将向量及其邻居的邻接列表一起存储以提升数据局部性；并在现有两种基于磁盘的系统上进行实验评估。

Result: 在实验中，Gorgeous相比两种最先进的基于磁盘的向量检索系统，平均查询吞吐量提升超过60%，查询延迟降低超过35%。

Conclusion: Gorgeous通过将邻接表缓存放入内存并在磁盘块中与向量一起存储邻居的邻接表，优先考虑图结构而非向量，实现了更高的查询吞吐量和更低的延迟。

Abstract: Similarity-based vector search underpins many important applications, but a
key challenge is processing massive vector datasets (e.g., in TBs). To reduce
costs, some systems utilize SSDs as the primary data storage. They employ a
proximity graph, which connects similar vectors to form a graph and is the
state-of-the-art index for vector search. However, these systems are hindered
by sub-optimal data layouts that fail to effectively utilize valuable memory
space to reduce disk access and suffer from poor locality for accessing
disk-resident data. Through extensive profiling and analysis, we found that the
structure of the proximity graph index is accessed more frequently than the
vectors themselves, yet existing systems do not distinguish between the two. To
address this problem, we design the Gorgeous system with the principle of
prioritizing graph structure over vectors. Specifically, Gorgeous features a
memory cache that keeps the adjacency lists of graph nodes to improve cache
hits and a disk block format that explicitly stores neighbors' adjacency lists
along with a vector to enhance data locality. Experimental results show that
Gorgeous consistently outperforms two state-of-the-art disk-based systems for
vector search, boosting average query throughput by over 60% and reducing query
latency by over 35%.

</details>


### [6] [GoVector: An I/O-Efficient Caching Strategy for High-Dimensional Vector Nearest Neighbor Search](https://arxiv.org/abs/2508.15694)
*Yijie Zhou,Shengyuan Lin,Shufeng Gong,Song Yu,Shuhao Fan,Yanfeng Zhang,Ge Yu*

Main category: cs.DB

TL;DR: GoVector通过静态+动态缓存及磁盘重排，显著降低磁盘图索引的I/O，提升ANNS查询效率。


<details>
  <summary>Details</summary>
Motivation: 在大规模基于图的ANNS中，内存不足导致索引需放在次级设备，频繁按需加载图与向量使I/O成为查询主瓶颈，现有静态缓存无法应对查询依赖的动态节点访问。

Method: 提出混合缓存策略：静态缓存保存入口点和频繁访问邻居；动态缓存自适应捕获第二阶段高空间局部性的节点；并重排磁盘存储，使相似向量共置于相邻页，从而提升磁盘读的局部性。

Result: 在多个公开数据集上实验表明：在90%召回下，平均减少46% I/O操作，查询吞吐提升1.73倍，查询延迟降低42%，优于最先进的磁盘图索引系统。

Conclusion: GoVector通过结合静态缓存与动态缓存并对磁盘节点重排，有效提高了基于图的磁盘向量索引的I/O效率，从而在高召回下显著降低I/O量、提升吞吐并减少延迟。

Abstract: Graph-based high-dimensional vector indices have become a mainstream solution
for large-scale approximate nearest neighbor search (ANNS). However, their
substantial memory footprint often requires storage on secondary devices, where
frequent on-demand loading of graph and vector data leads to I/O becoming the
dominant bottleneck, accounting for over 90\% of query latency. Existing static
caching strategies mitigate this issue only in the initial navigation phase by
preloading entry points and multi-hop neighbors, but they fail in the second
phase where query-dependent nodes must be dynamically accessed to achieve high
recall. We propose GoVector, an I/O-efficient caching strategy tailored for
disk-based graph indices. GoVector combines (1) a static cache that stores
entry points and frequently accessed neighbors, and (2) a dynamic cache that
adaptively captures nodes with high spatial locality during the second search
phase. To further align storage layout with similarity-driven search patterns,
GoVector reorders nodes on disk so that similar vectors are colocated on the
same or adjacent pages, thereby improving locality and reducing I/O overhead.
Extensive experiments on multiple public datasets show that GoVector achieves
substantial performance improvements. At 90% recall, it reduces I/O operations
by 46% on average, increases query throughput by 1.73x, and lowers query
latency by 42% compared to state-of-the-art disk-based graph indexing systems.

</details>
